# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-qw1rG-UrV0yplY97fXP10pX5HH6vtSE
"""

# KURULUM
!pip install groq gradio pillow requests huggingface_hub

#KullanÄ±cÄ± CÃ¼mlesi
#        â†“
#TÃ¼rkÃ§e HikÃ¢ye Ãœretimi (LLM)
#        â†“
#Karakter FÃ¶yÃ¼ + Sahne AyÄ±klama
#        â†“
#Her Sahne Ä°Ã§in GÃ¶rsel Prompt
#        â†“
#AI GÃ¶rsel Ãœretimi
#        â†“
#Web ArayÃ¼zÃ¼nde Kitap GÃ¶rÃ¼nÃ¼mÃ¼

# IMPORTLAR VE API ANAHTARLARI
import re
import io
import base64
import requests
from PIL import Image

import gradio as gr
from groq import Groq
from huggingface_hub import InferenceClient


GROQ_API_KEY = "**"
HF_TOKEN = "**"

groq_client = Groq(api_key=GROQ_API_KEY)

# HuggingFace FLUX (GÃ¶rsel Ã¼retim)
HF_IMAGE_MODEL = "black-forest-labs/FLUX.1-schnell"
hf_image = InferenceClient(HF_IMAGE_MODEL, token=HF_TOKEN)

# HÄ°KÃ‚YE ÃœRETÄ°M PROMPTU
# Bu prompt LLM Ã§Ä±ktÄ±sÄ±nÄ±n formatÄ±nÄ± kontrol eder.
# AmaÃ§:
# - TamamÄ± TÃ¼rkÃ§e
# - Uzun hikÃ¢ye
# - Karakter fÃ¶yÃ¼
# - Sahne listesi


STORY_SYSTEM_PROMPT = """
You are a professional children's storyteller with strict formatting rules.

IMPORTANT LANGUAGE RULE:
Even though the instructions are in English,
YOU MUST WRITE EVERYTHING IN NATURAL, FLUENT TURKISH.

Your task:
Turn the user's short sentence into:
â€¢ A long, emotional, 8â€“15 paragraph Turkish children's story
â€¢ A Turkish character sheet: â€œKARAKTER FÃ–YÃœâ€
â€¢ A Turkish scene list: â€œSAHNE BÃ–LÃœMLERÄ°â€ (2-3 sentences each)

OUTPUT FORMAT (MUST MATCH EXACTLY):

HÄ°KÃ‚YE:
[uzun TÃ¼rkÃ§e hikÃ¢ye]

KARAKTER FÃ–YÃœ:
[fiziksel Ã¶zellikler, kÄ±yafetler, kiÅŸilik]

SAHNE BÃ–LÃœMLERÄ°:
1) [Sahne]
2) [Sahne]
3) ...

IMPORTANT:
â€¢ All output must be in Turkish.
â€¢ No English inside the story.
"""

def generate_story(sentence: str, n_scenes: int) -> str:
    """
    Groq Ã¼zerinden LLaMA 3.3 70B ile TÃ¼rkÃ§e hikÃ¢ye Ã¼retir.
    """
    response = groq_client.chat.completions.create(
        model="llama-3.3-70b-versatile",
        messages=[
            {"role": "system", "content": STORY_SYSTEM_PROMPT},
            {"role": "user", "content": f"BaÅŸlangÄ±Ã§ cÃ¼mlesi: {sentence}\nSahne sayÄ±sÄ±: {n_scenes}"}
        ],
        temperature=0.7,
        max_tokens=4000,
    )
    return response.choices[0].message.content


# SAHNE VE KARAKTER AYIKLAMA
# Model Ã§Ä±ktÄ±sÄ±nÄ± ham metin olarak bÄ±rakmak yerine
# otomatik olarak sahne ve karakter bilgilerini ayrÄ±lÄ±r.

def extract_scenes(text: str):
    scenes = []
    for i, line in enumerate(text.splitlines()):
        line = line.strip()
        if re.match(r"^\d+\)\s+", line):
            scenes.append(line.split(")", 1)[1].strip())  # "1) ..." â†’ metni al
    return scenes

def extract_character_sheet(text: str):
    parts = re.split(r"KARAKTER FÃ–YÃœ\s*:", text, flags=re.IGNORECASE)
    if len(parts) < 2:
        return ""
    after = parts[1]
    before_scene = re.split(r"SAHNE BÃ–LÃœMLERÄ°", after, flags=re.IGNORECASE)[0]
    return before_scene.strip()

# GÃ–RSEL PROMPT ÃœRETÄ°MÄ°
# TÃ¼rkÃ§e sahne + TÃ¼rkÃ§e karakter bilgisi
# Ä°ngilizce gÃ¶rsel prompt'a dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r.
# Ã‡Ã¼nkÃ¼ gÃ¶rsel modeller Ä°ngilizce promptlarda daha stabildir.

VISUAL_SYSTEM_PROMPT = """
You are a senior visual prompt engineer for children's books.

TASK:
Convert a TURKISH scene + character sheet into ONE English visual prompt.

RULES:
- Respect character appearance exactly.
- Respect setting, time, lighting, emotion.
- Style: children's book, soft watercolor, pastel, warm tones.
- Output only ONE paragraph in ENGLISH.
"""

def scene_to_visual_prompt(scene_text: str, character_sheet: str) -> str:
    message = f"""
TURKISH CHARACTER SHEET:
{character_sheet}

TURKISH SCENE:
{scene_text}

NOW OUTPUT ONLY ONE ENGLISH VISUAL PROMPT:
"""
    response = groq_client.chat.completions.create(
        model="llama-3.3-70b-versatile",
        messages=[
            {"role": "system", "content": VISUAL_SYSTEM_PROMPT},
            {"role": "user", "content": message}
        ],
        temperature=0.4,
        max_tokens=400
    )
    return response.choices[0].message.content

# FLUX GÃ–RSEL ÃœRETÄ°MÄ°
def generate_image_from_prompt(prompt: str) -> Image.Image:
    """
    HuggingFace FLUX Ã§Ä±ktÄ±sÄ± hem bytes hem de PIL Image dÃ¶nebildiÄŸi iÃ§in
    ikisini de gÃ¼venli ÅŸekilde iÅŸleyen fonksiyon.
    """
    result = hf_image.text_to_image(
        prompt=prompt,
        width=768,
        height=768
    )

    if isinstance(result, (bytes, bytearray)):
        try:
            return Image.open(io.BytesIO(result)).convert("RGB")
        except:
            pass

    if isinstance(result, Image.Image):
        return result.convert("RGB")

    if isinstance(result, list):
        first = result[0]
        if isinstance(first, (bytes, bytearray)):
            return Image.open(io.BytesIO(first)).convert("RGB")
        if isinstance(first, Image.Image):
            return first.convert("RGB")

    raise ValueError("Unsupported image return type:", type(result))


# PIPELINE
def pipeline(sentence: str, scene_count: int):
    try:
        story = generate_story(sentence, scene_count)
        character_sheet = extract_character_sheet(story)
        scenes = extract_scenes(story)[:scene_count]

        html = f"<h2>HikÃ¢ye</h2><p>{story.replace('\n', '<br>')}</p>"
        images = []

        for i, scene in enumerate(scenes, 1):
            try:
                prompt = scene_to_visual_prompt(scene, character_sheet)
                img = generate_image_from_prompt(prompt)
                images.append(img)

                buf = io.BytesIO()
                img.save(buf, format="PNG")
                img_b64 = base64.b64encode(buf.getvalue()).decode()

                html += f"""
                <h3>Sahne {i}</h3>
                <img src="data:image/png;base64,{img_b64}" width="600"/>
                <p>{scene}</p>
                """

            except Exception as e:
                html += f"<p style='color:red;'>GÃ¶rsel hatasÄ± (Sahne {i}): {e}</p>"

        return html, images

    except Exception as e:
        return f"<h3 style='color:red;'>HATA: {e}</h3>", []

# GRADIO ARAYÃœZÃœ (KÄ°TAP TASARIMI)
with gr.Blocks(
    title="TÃ¼rkÃ§e Masal KitabÄ±",
    css="body { background:#f7efe3 }"
) as demo:

    gr.Markdown("""
    <h1 style="text-align:center; color:#5a381e;">ğŸ“š TÃ¼rkÃ§e Masal â†’ Sahne â†’ GÃ¶rsel Kitap</h1>
    """)

    sentence_in = gr.Textbox(label="BaÅŸlangÄ±Ã§ CÃ¼mlesi")
    scene_count_in = gr.Slider(1, 8, value=4, label="Sahne SayÄ±sÄ±")

    btn = gr.Button("ğŸ“˜ MasalÄ± OluÅŸtur")

    story_out = gr.HTML()
    images_out = gr.Gallery(columns=2)

    btn.click(
        pipeline,
        inputs=[sentence_in, scene_count_in],
        outputs=[story_out, images_out]
    )

demo.launch(share=True)